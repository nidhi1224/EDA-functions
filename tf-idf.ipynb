{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567ffe55-2d33-4942-a597-9a2ee88adc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f175ca53-e5f8-41e8-b061-b31bec5260e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens and POS Tags for sentence:\n",
      "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\n",
      "Data: NNP\n",
      "science: NN\n",
      "is: VBZ\n",
      "an: DT\n",
      "interdisciplinary: JJ\n",
      "field: NN\n",
      "that: WDT\n",
      "uses: VBZ\n",
      "scientific: JJ\n",
      "methods: NNS\n",
      ",: ,\n",
      "processes: NNS\n",
      ",: ,\n",
      "algorithms: NN\n",
      ",: ,\n",
      "and: CC\n",
      "systems: NNS\n",
      "to: TO\n",
      "extract: VB\n",
      "knowledge: NN\n",
      "and: CC\n",
      "insights: NNS\n",
      "from: IN\n",
      "structured: VBN\n",
      "and: CC\n",
      "unstructured: JJ\n",
      "data: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "It integrates various domains such as statistics, machine learning, data mining, and big data analytics.\n",
      "It: PRP\n",
      "integrates: VBZ\n",
      "various: JJ\n",
      "domains: NNS\n",
      "such: JJ\n",
      "as: IN\n",
      "statistics: NNS\n",
      ",: ,\n",
      "machine: NN\n",
      "learning: NN\n",
      ",: ,\n",
      "data: NN\n",
      "mining: NN\n",
      ",: ,\n",
      "and: CC\n",
      "big: JJ\n",
      "data: NNS\n",
      "analytics: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "Data science is essential for making informed decisions in business, healthcare, finance, and many other industries.\n",
      "Data: NNP\n",
      "science: NN\n",
      "is: VBZ\n",
      "essential: JJ\n",
      "for: IN\n",
      "making: VBG\n",
      "informed: JJ\n",
      "decisions: NNS\n",
      "in: IN\n",
      "business: NN\n",
      ",: ,\n",
      "healthcare: NN\n",
      ",: ,\n",
      "finance: NN\n",
      ",: ,\n",
      "and: CC\n",
      "many: JJ\n",
      "other: JJ\n",
      "industries: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "It involves data collection, data cleaning, data analysis, and data visualization.\n",
      "It: PRP\n",
      "involves: VBZ\n",
      "data: NNS\n",
      "collection: NN\n",
      ",: ,\n",
      "data: NNS\n",
      "cleaning: NN\n",
      ",: ,\n",
      "data: NN\n",
      "analysis: NN\n",
      ",: ,\n",
      "and: CC\n",
      "data: NNS\n",
      "visualization: NN\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "Data scientists use programming languages like Python and R to perform data analysis.\n",
      "Data: NNP\n",
      "scientists: NNS\n",
      "use: VBP\n",
      "programming: VBG\n",
      "languages: NNS\n",
      "like: IN\n",
      "Python: NNP\n",
      "and: CC\n",
      "R: NNP\n",
      "to: TO\n",
      "perform: VB\n",
      "data: NNS\n",
      "analysis: NN\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "They also employ tools such as Hadoop, Spark, and SQL for handling large datasets.\n",
      "They: PRP\n",
      "also: RB\n",
      "employ: VBP\n",
      "tools: NNS\n",
      "such: JJ\n",
      "as: IN\n",
      "Hadoop: NNP\n",
      ",: ,\n",
      "Spark: NNP\n",
      ",: ,\n",
      "and: CC\n",
      "SQL: NNP\n",
      "for: IN\n",
      "handling: VBG\n",
      "large: JJ\n",
      "datasets: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "The ultimate goal of data science is to uncover hidden patterns, correlations, and trends.\n",
      "The: DT\n",
      "ultimate: JJ\n",
      "goal: NN\n",
      "of: IN\n",
      "data: NNS\n",
      "science: NN\n",
      "is: VBZ\n",
      "to: TO\n",
      "uncover: VB\n",
      "hidden: JJ\n",
      "patterns: NNS\n",
      ",: ,\n",
      "correlations: NNS\n",
      ",: ,\n",
      "and: CC\n",
      "trends: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "By doing so, it helps organizations improve their operations and strategies.\n",
      "By: IN\n",
      "doing: VBG\n",
      "so: RB\n",
      ",: ,\n",
      "it: PRP\n",
      "helps: VBZ\n",
      "organizations: NNS\n",
      "improve: VB\n",
      "their: PRP$\n",
      "operations: NNS\n",
      "and: CC\n",
      "strategies: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "Data science is a rapidly growing field, with increasing demand for skilled professionals.\n",
      "Data: NNP\n",
      "science: NN\n",
      "is: VBZ\n",
      "a: DT\n",
      "rapidly: RB\n",
      "growing: VBG\n",
      "field: NN\n",
      ",: ,\n",
      "with: IN\n",
      "increasing: VBG\n",
      "demand: NN\n",
      "for: IN\n",
      "skilled: JJ\n",
      "professionals: NNS\n",
      ".: .\n",
      "\n",
      "\n",
      "Tokens and POS Tags for sentence:\n",
      "It is transforming the way we understand and interact with data, leading to more accurate predictions and better decision-making.\n",
      "It: PRP\n",
      "is: VBZ\n",
      "transforming: VBG\n",
      "the: DT\n",
      "way: NN\n",
      "we: PRP\n",
      "understand: VBP\n",
      "and: CC\n",
      "interact: VBP\n",
      "with: IN\n",
      "data: NNS\n",
      ",: ,\n",
      "leading: VBG\n",
      "to: TO\n",
      "more: RBR\n",
      "accurate: JJ\n",
      "predictions: NNS\n",
      "and: CC\n",
      "better: JJR\n",
      "decision-making: NN\n",
      ".: .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Combined sentences\n",
    "combined_sentences = [\n",
    "    \"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\",\n",
    "    \"It integrates various domains such as statistics, machine learning, data mining, and big data analytics.\",\n",
    "    \"Data science is essential for making informed decisions in business, healthcare, finance, and many other industries.\",\n",
    "    \"It involves data collection, data cleaning, data analysis, and data visualization.\",\n",
    "    \"Data scientists use programming languages like Python and R to perform data analysis.\",\n",
    "    \"They also employ tools such as Hadoop, Spark, and SQL for handling large datasets.\",\n",
    "    \"The ultimate goal of data science is to uncover hidden patterns, correlations, and trends.\",\n",
    "    \"By doing so, it helps organizations improve their operations and strategies.\",\n",
    "    \"Data science is a rapidly growing field, with increasing demand for skilled professionals.\",\n",
    "    \"It is transforming the way we understand and interact with data, leading to more accurate predictions and better decision-making.\"\n",
    "]\n",
    "\n",
    "for sentence in combined_sentences:\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "    \n",
    "    # Perform POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Print the tokens with their POS tags\n",
    "    print(\"Tokens and POS Tags for sentence:\")\n",
    "    print(sentence)\n",
    "    for token, tag in pos_tags:\n",
    "        print(f\"{token}: {tag}\")\n",
    "    print(\"\\n\")  # Add a newline for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca244c55-0ddb-4219-ab34-b2b58ac32957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document: Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\n",
      "Text After HTML Removal: data science is an interdisciplinary field that uses scientific methods processes algorithms and systems to extract knowledge and insights from structured and unstructured data\n",
      "Tokens: ['data', 'science', 'is', 'an', 'interdisciplinary', 'field', 'that', 'uses', 'scientific', 'methods', 'processes', 'algorithms', 'and', 'systems', 'to', 'extract', 'knowledge', 'and', 'insights', 'from', 'structured', 'and', 'unstructured', 'data']\n",
      "Filtered Tokens: ['data', 'science', 'interdisciplinary', 'field', 'uses', 'scientific', 'methods', 'processes', 'algorithms', 'systems', 'extract', 'knowledge', 'insights', 'structured', 'unstructured', 'data']\n",
      "Stemmed Tokens: ['data', 'scienc', 'interdisciplinari', 'field', 'use', 'scientif', 'method', 'process', 'algorithm', 'system', 'extract', 'knowledg', 'insight', 'structur', 'unstructur', 'data']\n",
      "Lemmatized Tokens: ['data', 'science', 'interdisciplinary', 'field', 'us', 'scientific', 'method', 'process', 'algorithm', 'system', 'extract', 'knowledge', 'insight', 'structure', 'unstructured', 'data']\n",
      "--------------------------------------------------\n",
      "Original Document: It integrates various domains such as statistics, machine learning, data mining, and big data analytics.\n",
      "Text After HTML Removal: it integrates various domains such as statistics machine learning data mining and big data analytics\n",
      "Tokens: ['it', 'integrates', 'various', 'domains', 'such', 'as', 'statistics', 'machine', 'learning', 'data', 'mining', 'and', 'big', 'data', 'analytics']\n",
      "Filtered Tokens: ['integrates', 'various', 'domains', 'statistics', 'machine', 'learning', 'data', 'mining', 'big', 'data', 'analytics']\n",
      "Stemmed Tokens: ['integr', 'variou', 'domain', 'statist', 'machin', 'learn', 'data', 'mine', 'big', 'data', 'analyt']\n",
      "Lemmatized Tokens: ['integrates', 'various', 'domain', 'statistic', 'machine', 'learn', 'data', 'mining', 'big', 'data', 'analytics']\n",
      "--------------------------------------------------\n",
      "Original Document: Data science is essential for making informed decisions in business, healthcare, finance, and many other industries.\n",
      "Text After HTML Removal: data science is essential for making informed decisions in business healthcare finance and many other industries\n",
      "Tokens: ['data', 'science', 'is', 'essential', 'for', 'making', 'informed', 'decisions', 'in', 'business', 'healthcare', 'finance', 'and', 'many', 'other', 'industries']\n",
      "Filtered Tokens: ['data', 'science', 'essential', 'making', 'informed', 'decisions', 'business', 'healthcare', 'finance', 'many', 'industries']\n",
      "Stemmed Tokens: ['data', 'scienc', 'essenti', 'make', 'inform', 'decis', 'busi', 'healthcar', 'financ', 'mani', 'industri']\n",
      "Lemmatized Tokens: ['data', 'science', 'essential', 'make', 'inform', 'decision', 'business', 'healthcare', 'finance', 'many', 'industry']\n",
      "--------------------------------------------------\n",
      "Original Document: It involves data collection, data cleaning, data analysis, and data visualization.\n",
      "Text After HTML Removal: it involves data collection data cleaning data analysis and data visualization\n",
      "Tokens: ['it', 'involves', 'data', 'collection', 'data', 'cleaning', 'data', 'analysis', 'and', 'data', 'visualization']\n",
      "Filtered Tokens: ['involves', 'data', 'collection', 'data', 'cleaning', 'data', 'analysis', 'data', 'visualization']\n",
      "Stemmed Tokens: ['involv', 'data', 'collect', 'data', 'clean', 'data', 'analysi', 'data', 'visual']\n",
      "Lemmatized Tokens: ['involves', 'data', 'collection', 'data', 'cleaning', 'data', 'analysis', 'data', 'visualization']\n",
      "--------------------------------------------------\n",
      "Original Document: Data scientists use programming languages like Python and R to perform data analysis.\n",
      "Text After HTML Removal: data scientists use programming languages like python and r to perform data analysis\n",
      "Tokens: ['data', 'scientists', 'use', 'programming', 'languages', 'like', 'python', 'and', 'r', 'to', 'perform', 'data', 'analysis']\n",
      "Filtered Tokens: ['data', 'scientists', 'use', 'programming', 'languages', 'like', 'python', 'r', 'perform', 'data', 'analysis']\n",
      "Stemmed Tokens: ['data', 'scientist', 'use', 'program', 'languag', 'like', 'python', 'r', 'perform', 'data', 'analysi']\n",
      "Lemmatized Tokens: ['data', 'scientist', 'use', 'program', 'language', 'like', 'python', 'r', 'perform', 'data', 'analysis']\n",
      "--------------------------------------------------\n",
      "Original Document: They also employ tools such as Hadoop, Spark, and SQL for handling large datasets.\n",
      "Text After HTML Removal: they also employ tools such as hadoop spark and sql for handling large datasets\n",
      "Tokens: ['they', 'also', 'employ', 'tools', 'such', 'as', 'hadoop', 'spark', 'and', 'sql', 'for', 'handling', 'large', 'datasets']\n",
      "Filtered Tokens: ['also', 'employ', 'tools', 'hadoop', 'spark', 'sql', 'handling', 'large', 'datasets']\n",
      "Stemmed Tokens: ['also', 'employ', 'tool', 'hadoop', 'spark', 'sql', 'handl', 'larg', 'dataset']\n",
      "Lemmatized Tokens: ['also', 'employ', 'tool', 'hadoop', 'spark', 'sql', 'handle', 'large', 'datasets']\n",
      "--------------------------------------------------\n",
      "Original Document: The ultimate goal of data science is to uncover hidden patterns, correlations, and trends.\n",
      "Text After HTML Removal: the ultimate goal of data science is to uncover hidden patterns correlations and trends\n",
      "Tokens: ['the', 'ultimate', 'goal', 'of', 'data', 'science', 'is', 'to', 'uncover', 'hidden', 'patterns', 'correlations', 'and', 'trends']\n",
      "Filtered Tokens: ['ultimate', 'goal', 'data', 'science', 'uncover', 'hidden', 'patterns', 'correlations', 'trends']\n",
      "Stemmed Tokens: ['ultim', 'goal', 'data', 'scienc', 'uncov', 'hidden', 'pattern', 'correl', 'trend']\n",
      "Lemmatized Tokens: ['ultimate', 'goal', 'data', 'science', 'uncover', 'hidden', 'pattern', 'correlation', 'trend']\n",
      "--------------------------------------------------\n",
      "Original Document: By doing so, it helps organizations improve their operations and strategies.\n",
      "Text After HTML Removal: by doing so it helps organizations improve their operations and strategies\n",
      "Tokens: ['by', 'doing', 'so', 'it', 'helps', 'organizations', 'improve', 'their', 'operations', 'and', 'strategies']\n",
      "Filtered Tokens: ['helps', 'organizations', 'improve', 'operations', 'strategies']\n",
      "Stemmed Tokens: ['help', 'organ', 'improv', 'oper', 'strategi']\n",
      "Lemmatized Tokens: ['help', 'organization', 'improve', 'operation', 'strategy']\n",
      "--------------------------------------------------\n",
      "Original Document: Data science is a rapidly growing field, with increasing demand for skilled professionals.\n",
      "Text After HTML Removal: data science is a rapidly growing field with increasing demand for skilled professionals\n",
      "Tokens: ['data', 'science', 'is', 'a', 'rapidly', 'growing', 'field', 'with', 'increasing', 'demand', 'for', 'skilled', 'professionals']\n",
      "Filtered Tokens: ['data', 'science', 'rapidly', 'growing', 'field', 'increasing', 'demand', 'skilled', 'professionals']\n",
      "Stemmed Tokens: ['data', 'scienc', 'rapidli', 'grow', 'field', 'increas', 'demand', 'skill', 'profession']\n",
      "Lemmatized Tokens: ['data', 'science', 'rapidly', 'grow', 'field', 'increase', 'demand', 'skilled', 'professional']\n",
      "--------------------------------------------------\n",
      "Original Document: It is transforming the way we understand and interact with data, leading to more accurate predictions and better decision-making.\n",
      "Text After HTML Removal: it is transforming the way we understand and interact with data leading to more accurate predictions and better decisionmaking\n",
      "Tokens: ['it', 'is', 'transforming', 'the', 'way', 'we', 'understand', 'and', 'interact', 'with', 'data', 'leading', 'to', 'more', 'accurate', 'predictions', 'and', 'better', 'decisionmaking']\n",
      "Filtered Tokens: ['transforming', 'way', 'understand', 'interact', 'data', 'leading', 'accurate', 'predictions', 'better', 'decisionmaking']\n",
      "Stemmed Tokens: ['transform', 'way', 'understand', 'interact', 'data', 'lead', 'accur', 'predict', 'better', 'decisionmak']\n",
      "Lemmatized Tokens: ['transform', 'way', 'understand', 'interact', 'data', 'lead', 'accurate', 'prediction', 'well', 'decisionmaking']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize the Porter Stemmer and WordNet Lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\",\n",
    "    \"It integrates various domains such as statistics, machine learning, data mining, and big data analytics.\",\n",
    "    \"Data science is essential for making informed decisions in business, healthcare, finance, and many other industries.\",\n",
    "    \"It involves data collection, data cleaning, data analysis, and data visualization.\",\n",
    "    \"Data scientists use programming languages like Python and R to perform data analysis.\",\n",
    "    \"They also employ tools such as Hadoop, Spark, and SQL for handling large datasets.\",\n",
    "    \"The ultimate goal of data science is to uncover hidden patterns, correlations, and trends.\",\n",
    "    \"By doing so, it helps organizations improve their operations and strategies.\",\n",
    "    \"Data science is a rapidly growing field, with increasing demand for skilled professionals.\",\n",
    "    \"It is transforming the way we understand and interact with data, leading to more accurate predictions and better decision-making.\"\n",
    "]\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Apply stemming\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    # Apply lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in filtered_tokens]\n",
    "    return {\n",
    "        'original': text,\n",
    "        'tokens': tokens,\n",
    "        'filtered_tokens': filtered_tokens,\n",
    "        'stemmed_tokens': stemmed_tokens,\n",
    "        'lemmatized_tokens': lemmatized_tokens\n",
    "    }\n",
    "\n",
    "# Function to get the part of speech tag for lemmatization\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Process each document in the corpus\n",
    "for document in corpus:\n",
    "    result = preprocess_text(document)\n",
    "    print(\"Original Document:\", document)\n",
    "    print(\"Text After HTML Removal:\", result['original'])\n",
    "    print(\"Tokens:\", result['tokens'])\n",
    "    print(\"Filtered Tokens:\", result['filtered_tokens'])\n",
    "    print(\"Stemmed Tokens:\", result['stemmed_tokens'])\n",
    "    print(\"Lemmatized Tokens:\", result['lemmatized_tokens'])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e47bb8-b64a-412c-9914-d14788ddc0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Reviews:\n",
      " 0      review 1: this movie is very scary and long.\n",
      "1    review 2: this movie is not scary and is slow.\n",
      "2          review 3: this movie is spooky and good.\n",
      "Name: Review, dtype: object\n",
      "\n",
      "One-Hot Encoded:\n",
      " [[1 0 1 1 1 0 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 1 1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0 1 0 0 1 1 0]]\n",
      "Vocabulary: ['and' 'good' 'is' 'long' 'movie' 'not' 'review' 'scary' 'slow' 'spooky'\n",
      " 'this' 'very']\n",
      "\n",
      "Bag of Words:\n",
      " [[1 0 1 1 1 0 1 1 0 0 1 1]\n",
      " [1 0 2 0 1 1 1 1 1 0 1 0]\n",
      " [1 1 1 0 1 0 1 0 0 1 1 0]]\n",
      "Vocabulary: ['and' 'good' 'is' 'long' 'movie' 'not' 'review' 'scary' 'slow' 'spooky'\n",
      " 'this' 'very']\n",
      "\n",
      "TF-IDF:\n",
      " [[0.28407693 0.         0.28407693 0.48098405 0.28407693 0.\n",
      "  0.28407693 0.36580076 0.         0.         0.28407693 0.48098405]\n",
      " [0.25489296 0.         0.50978591 0.         0.25489296 0.43157129\n",
      "  0.25489296 0.32822109 0.43157129 0.         0.25489296 0.        ]\n",
      " [0.30523155 0.51680194 0.30523155 0.         0.30523155 0.\n",
      "  0.30523155 0.         0.         0.51680194 0.30523155 0.        ]]\n",
      "Vocabulary: ['and' 'good' 'is' 'long' 'movie' 'not' 'review' 'scary' 'slow' 'spooky'\n",
      " 'this' 'very']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample reviews\n",
    "data ={ \n",
    "    \"Review\": [\n",
    "        \"Review 1: This movie is very scary and long.\",\n",
    "        \"Review 2: This movie is not scary and is slow.\",\n",
    "        \"Review 3: This movie is spooky and good.\"\n",
    "        ] }\n",
    "    \n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert to lowercase\n",
    "df['Review'] = df['Review'].str.lower()\n",
    "\n",
    "# One-Hot Encoding\n",
    "one_hot_encoder = CountVectorizer(binary=True)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(df['Review'])\n",
    "\n",
    "# Bag of Words\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_encoded = count_vectorizer.fit_transform(df['Review'])\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_encoded = tfidf_vectorizer.fit_transform(df['Review'])\n",
    "\n",
    "# Output Results\n",
    "print(\"Original Reviews:\\n\", df['Review'])\n",
    "print(\"\\nOne-Hot Encoded:\\n\", one_hot_encoded.toarray())\n",
    "print(\"Vocabulary:\", one_hot_encoder.get_feature_names_out())\n",
    "\n",
    "print(\"\\nBag of Words:\\n\", bow_encoded.toarray())\n",
    "print(\"Vocabulary:\", count_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF:\\n\", tfidf_encoded.toarray())\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be12d7-70f0-408b-9a5d-7e0a51675335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
